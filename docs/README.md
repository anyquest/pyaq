# Getting Started with PyAQ

PyAQ apps are defined as YAML documents consisting of the following sections: 

- header 
- info 
- models 
- tools 
- memory
- activities 

The tools section is optional. 

## Header 

The header section is a single line of the form: 

```
aq: 0.0.1
```

The number in the header is the PyAQ version number. 

## Info 

The info section is a YAML object with the following properties: 

- **id**: A unique identifier for the app 
- **version**: The version number of the app 
- **title**: The app's title 
- **profile**: The profile assumed by the large language model processing requests on behalf of the app. 

For example: 

```
info:
  id: aq.apps.accident_report
  version: 1.0.0
  title: Accident Report Application
  profile: >
    You are an auto insurance adjuster. Your job is to assess the vehicle damage at the site of an accident.
```

## Models 

The models section consists of any number of subsections, one per model: 

```
models:
    model_1: <model_1 definition>
    model_2: <model_2 definition>
    ...
    model_n: <model_n definition>
```

A model definition section has the following properties: 

- **model**: The name of the model, e.g. gpt-4. This name is AI provider specific. 
- **provider**: The name of the model provider. Use openai for OpenAI and anthropic for Anthropic. 
- **parameters**: The optional list of parameters passed to the model 
    - **temperature**: The sampling temperature, between 0 and 2. 
    - **max_tokens**: The maximum number of tokens that can be generated by the model 

Consult AI provider documentation for the list of model names. As of this writing, for OpenAI, the list of recommended models includes: 

- **gpt-4-0125-preview** - the latest GPT-4 class model 
- **gpt-4-vision-preview** - GPT-4 with the ability to understand images

Here is an example of the models section: 

```
models:
  vision-model:
    model: gpt-4-vision-preview
    provider: openai
    parameters:
        temperature: 0.8
        max_tokens: 3000
  gpt-4:
    model: gpt-4-0125-preview
    provider: openai
```

## Tools

The tools section describes the tools that can be used to AI models to carry out work on behalf of the app. It consists of any number of subsections, one per tool. 

```
tools:
    tool_1: <tool_1 definition>
    tool_2: <tool_2 definition>
    ...
    tool_n: <tool_n definition>
```

A tool definition section has the following properties: 

- **type**: The type of the tool. At the time of this writing, "web" is the only tool type supported by PyAQ.

The web tool enables large language models to search the web for keywords and summarize web pages. 

Here is an example of the tools section: 

```
tools:
  websearch:
    type: web
```

### Memory 

An application can store text in one or more long-term memory repositories. The repositories are declared in the memory section of the application definition. The memory section consists of any number of subsections, one per memory repository: 

```
memory:
    repository_1: <repository_1 definition>
    repository_2: <repository_2 definition>
    ...
    repository_n: <repository_n definition>
```

A repository definition section has the following properties: 

- **type**: The type of the repository. At the time of this writing, "chromadb" is the only type supported. 
- **parameters**: The list of parameters
    - **chunk_size**: The size of each text chunk stored in the repository, measured in symbols. Default value: 2000

Here is an example of the memory section: 

```
memory:
  vector:
    type: chromadb
    parameters:
      chunk_size: 1000
```

## Activities

The activities section describes the activities are performed by the application. 

Each activity has one or more inputs and one output. Activities are connected into flows, directed acyclic graphs, with outputs of one activity sending information to several other activities. 

An activity is executed by only when all of its inputs are available. Several activities can be executing in parallel. 

An application starts by executing activities that have no inputs. Application ends when there are no more activities that can be executed.

The activities section consists of any number subsections, one per activity. 

```
activities:
    activity_1: <activity_1 definition>
    activity_2: <activity_2 definition>
    ... 
    activity_n: <activity_n definition>
```

An activity definition has the following properties: 

- **type**: The type of the activity. PyAQ supports the following types of activities:
    - **read**: Read the application's input stream, extract text, and produce text as output
    - **write**: Merge inputs, apply formatting, and write the result to the application's output stream 
    - **summarize**: Summarize inputs and send the summary to the output
    - **extract**: Extract information from inputs and send it to the output 
    - **merge**: Merge inputs, apply template and formatting, and send the result to the output
    - **generate**: Combine inputs with a prompt, use the prompt to generate text using a large language model, and send the result to the output 
    - **store**: Combine inputs and store the result in the application's long-term memory
    - **retrieve**: Combine inputs and use the result as a query to retrieve relevant content from the long-term memory 
- **inputs**: The list of activities that serve as inputs for this activity. Each entry in this list has two properties:
    - **activity**: The name of an input activity
    - **map**: If present, spawns retrieves a JSON array using the JSON path provided as value and spawns a separate instance of this activity for each element of the array. The dollar sign \$ refers to the root of the input object. The expression can refer to an array property deep in the input, e.g. $.property_1.property_2.
- **models**: The list of models that can be used by the activity to perform its work. Each entry in the list is the name of a model from the models section of the app definition. At the moment, the models list can have at most one model. 
- **tools**: The list of tools that can be used by the model to perform work on behave of the activity. Each entry in the list is the name of a tool from the tools section of the app definition.
- **memory**: The list of long-term memory repositories that are used by this activity to store or retrieve content. Each entry in the list is the name of a repository from the memory section of the app definition. 
- **parameters**: The list of activity specific parameters. Each parameter is represented with a separate property.

Only the **type** property is required. All other properties are optional. 

Next, we provide activity specific information. 

### read

The read activity does not have any activity specific parameters. 

Here is an example of the read activity: 
```
  read_content:
    type: read
```

### write

The write activity has two parameters: 

- **filename**: The name of the output file. 
- **format**: The format of the output. The value can be one of the following: 
    - **html**: HTML cotent 
    - **json**: A string in JSON format 
    - **md**: Markdown content 
- **template**: The template that is used to merge inputs before applying formatting. 

All parameters are optional. 

If the filename parameter is not provided, a unique file name is generated automatically. 

If the format parameter is not provided, **md** is assumed as its default value.

The template string must be provided in the Markdown format. It can include references to input activities, where each reference is the name of an input activity inclosed in double curly braces, e.g. {{some_intput_activity}}. An activity reference is replaced with the output of that activity in the template. 

If the input activity produces a JSON object, then the activity reference can be a path experession referring to a property deep in the object. For example: {{some_input_activity.property_1.property_2}}.

If a template string is not provided, then the behavior of the write activity depends on the value of the format parameter. For JSON strings, inputs are combined into a JSON array. For all other formats, inputs are concatenated to produce an output.

Here is an example of a write activity: 

```
  write_summary:
    type: write
    inputs:
      - activity: create_summary
      - activity: generate_strategies
    parameters:
      format: html
      template: |
        ## SUMMARY
        {{create_summary}}
        
        ## STRATEGIES
        {{generate_strategies}}
```

### merge 

The merge activity takes two parameters: **format** and **template**. Their meaning is identical to the corresponding parameters of the write activity. 


### summarize 

The summarize activity has two parameters: 

- **sentences**: The number sentences to include in the summary. Default value: 10
- **temperature**: The sampling temperature, value between 0 and 2, that is used by the large languge model when creating a summary. Default value: 0.5

The summarize activity always produces output in the Markdown format.

Here is an example of a summarize activity: 

```
  create_summary:
    type: summarize
    inputs:
      - activity: read_content
    parameters:
      temperature: 0.5
      sentences: 5
    models:
      - gpt4
```

### extract

The extract activity has only one parameter: 

- **schema**: The list of type definitions, where each type has the following properties: 
    - **name**: The name of the type 
    - **description**: The description of the type 
    - **paramteres**: The list of type parameters: 
        - **required**: The list of names of the type properties that must be present in the output
        - **properties**: The list of property descriptors, where the name of the descriptor serves as the property name. Each property descriptor has a subproperty called **description** describing the property. A property name must be one word in lower case with no spaces.

Here is an example of extract activity: 

```
  extract_contacts:
    type: extract
    inputs:
      - activity: read_content
    models:
      - gpt4
    parameters:
      schema:
        - name: Contact
          description: Contact information for a person mentioned in the text
          parameters:
            required:
              - name
              - email
            properties:
              name:
                description: Contact's name
              title:
                description: Contact's position or title
              company:
                description: Contact's place of work
              email:
                description: Contact's email address
              phone:
                description: Contact's telephone number
```

### generate

The generate activity has two parameters: 

- **format**: The desired format of the activity output with values from this list: 
    - **json**: A string in JSON format 
    - **md**: Markdown content 
- **prompt**: The template of the prompt that is forwarded to the large language model. 

The format parameter is optional. If it is not present, the value of **md** is assumed by default. 

The prompt template is required. It must be provided in the Markdown format. 

The template can include references to input activities, where each reference is the name of an input activity inclosed in double curly braces, e.g. {{some_intput_activity}}. An activity reference is replaced with the output of that activity in the prompt template. 

If the input activity produces a JSON object, then the activity reference can be a path experession referring to a property deep in the object. For example: {{some_input_activity.property_1.property_2}}.

Here is an example of the generate activity: 

```
  summarize_interests:
    type: generate
    inputs:
      - activity: read_request
    tools:
      - websearch
    models:
      - gpt4
    parameters:
      prompt: |
        Here is a list of pages visited by a prospect on our website:
        {{read_request.pages}}
        Visit each link and create a brief summary of the prospect's interests in
        our company, products, and services. In particular, I am interested
        in the business problem that the prospect is trying to solve.
```

### store 

The store activity breaks long texts into chunks and stores each chunk in the application's long-term memory. Long-term memory is shared by all instances of the application. The chunks are mapped to embeddings and stored in the index database.

The store activity has one parameter: 

- **chunk_size**: The size of text chunk in symbols. Default value: 2000  

Here is an example of the store activity: 

```
  store_content:
    type: store
    memory:
      - vector
    inputs:
      - activity: read_content
```

### retrieve 

The retrieve activity calculate an embedding for its combined inputs and uses this embedding to retrieve matching chunks from the long-term memory. 

The retrieve activity has one parameter: 

- **n_results**: The number of matching chunks to retrieve. Default value: 3

Matching chunks are concatenated for form the output of the retrieve activity.

Here is an example of the retrieve activity: 

```
  retrieve_context:
    type: retrieve
    memory:
      - vector
    inputs:
      - activity: read_question
    parameters:
      n_results: 3
```

## Examples

### Philosophical Q&A

This application reads a question from the application input, forwards this question to a large language model, and saves the model's answer in the application's output. Note that the write_answer activity combines inputs from two activities, read_question and answer_question. The model is asked to assume the profile of a philosopher. 

```
aq: 0.0.1

info:
  id: aq.apps.meaning_of_life
  version: 1.0.0
  title: Meaning of Life
  profile: >
    You are a philosopher with a knack for resolving existential questions.

models:
  gemini:
    model: gpt-4-0125-preview
    provider: openai

activities:
  read_question:
    type: read

  answer_question:
    type: generate
    inputs:
      - activity: read_question
    models:
      - gemini
    parameters:
      temperature: 0.8
      prompt: >
        Answer this question like a true philosopher would: {{read_question}}

  write_answer:
    type: write
    inputs:
      - activity: read_question
      - activity: answer_question
    parameters:
      format: html
      template: |
        ## QUESTION:
        {{read_question}}
        
        ## ANSWER
        {{answer_question}}
```

### Contact Information Extraction

This application is asked to extract contact information from application's input. The result is saved in JSON format.

```
aq: 0.0.1

info:
  id: aq.apps.extract
  version: 1.0.0
  title: Contact Extraction Agent
  profile: >
    You are an expert at reading text and extracting useful information.

models:
  gpt4:
    model: gpt-4-0125-preview
    provider: openai

activities:
  read_content:
    type: read

  extract_contacts:
    type: extract
    inputs:
      - activity: read_content
    models:
      - gpt4
    parameters:
      schema:
        - name: Contact
          description: Contact information for a person mentioned in the text
          parameters:
            required:
              - name
              - email
            properties:
              name:
                description: Contact's name
              title:
                description: Contact's position or title
              company:
                description: Contact's place of work
              email:
                description: Contact's email address
              phone:
                description: Contact's telephone number

  save_contacts:
    type: write
    inputs:
      - activity: extract_contacts
    parameters:
      format: json
```

### Vehicle Damage Assessment 

This application is asked to view a photograph taken at the place of an accident and assess the damage sustained by the vehicle. The model is asked to assume the profile of an insurance adjuster. 

Note how the image is included in the application's output. 

```
aq: 0.0.1

info:
  id: aq.apps.accident_report
  version: 1.0.0
  title: Accident Report Application
  profile: >
    You are an auto insurance adjuster. Your job is to assess the vehicle damage at the site of an accident.

models:
  vision-model:
    model: gpt-4-vision-preview
    provider: openai

activities:
  read_image:
    type: read

  report_damage:
    type: generate
    inputs:
      - activity: read_image
    models:
      - vision-model
    parameters:
      temperature: 0.5
      prompt: >
        Provide a detailed description of the damage to the vehicle in the attached image. 

  write_answer:
    type: write
    inputs:
      - activity: read_image
      - activity: report_damage
    parameters:
      format: html
      template: |
        ## DAMAGE REPORT
        ![Vehicle]({{read_image}})
        
        {{report_damage}}
```

### Retrieval-augmented Generation 

This application is used to answer questions based on information in documents stored in the application's long-term memory. One group of interconnected activities is used to read application's input and save it in the long-term memory. Another group of interconnected activities is used to retrieve relevant chunks from memory to answer a question. The question and the answer are saved in HTML format.

```
aq: 0.0.1

info:
  id: aq.apps.rag
  version: 1.0.0
  title: Retrieval-augmented Generation Agent
  profile: >
    You are a chief investment officer at a large asset management firm.
    Respond to questions accordingly.

models:
  gpt-4:
    model: gpt-4-0125-preview
    provider: openai

memory:
  vector:
    type: chromadb
    parameters:
      chunk_size: 1000

activities:
  # STORE CONTENT IN AGENT'S MEMORY
  read_content:
    type: read

  store_content:
    type: store
    memory:
      - vector
    inputs:
      - activity: read_content

  # ANSWER QUESTIONS USING INFO IN AGENT'S MEMORY
  read_question:
    type: read

  retrieve_context:
    type: retrieve
    memory:
      - vector
    inputs:
      - activity: read_question
    parameters:
      n_results: 3

  answer_question:
    type: generate
    inputs:
      - activity: read_question
      - activity: retrieve_context
    models:
      - gpt-4
    parameters:
      temperature: 0.5
      prompt: |
        Context:
        {{retrieve_context}}
        
        Question:  
        {{read_question}}

  write_answer:
    type: write
    inputs:
      - activity: read_question
      - activity: answer_question
    parameters:
      format: html
      template: |
        ## QUESTION        
        {{read_question}}
        
        ## ANSWER
        {{answer_question}}
```

### Lead Research 

This application takes a list of contacts as inputs and searches the web to find URLs of their LinkedIn profiles. The input is a list of JSON objects. The map property is used to map each object to a separate instance of the enrich_contacts activity. The outputs of all instances are combined into a JSON array by the save_contacts activity. 

```
aq: 0.0.1

info:
  id: aq.apps.enrich
  version: 1.0.0
  title: Contact Enrichment Agent
  profile: >
    You are virtual research assistant. You can search the web to find more information about people.

models:
  gpt4:
    model: gpt-4-1106-preview
    provider: openai

tools:
  websearch:
    type: web

activities:
  read_content:
    type: read

  enrich_contacts:
    type: generate
    inputs:
      - activity: read_content
        map: $
    tools:
      - websearch
    models:
      - gpt4
    parameters:
      format: json
      prompt: |
        Here is a JSON object describing a contact: {{read_content}}.
        Use the web search tool to find a link to their LinkedIn page. 
        If found, add this link as the value of the 'linkedin' property to the JSON object 
        and produce this object as the result.

  save_contacts:
    type: write
    inputs:
      - activity: enrich_contacts
    parameters:
      format: json
```
